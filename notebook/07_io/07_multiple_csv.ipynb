{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3001fb91",
   "metadata": {},
   "source": [
    "# Working with multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13085b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "pl.Config.set_tbl_rows(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0fb6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"data/titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e20a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4abf763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the new directory\n",
    "csv_directory = Path(\"data/csv/multiple_csv\")\n",
    "\n",
    "csv_directory.mkdir(parents=True,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79464944",
   "metadata": {},
   "source": [
    "Split `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017144cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:700].write_csv(csv_directory / \"train.csv\")\n",
    "df[700:].write_csv(csv_directory / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b148d",
   "metadata": {},
   "source": [
    "## Eager mode\n",
    "\n",
    "### Reading multiple files with wildcard patterns\n",
    "\n",
    "Read multiple CSV files with the same schema using a wildcard `*` pattern, the files are alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3896ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>701</td><td>1</td><td>1</td><td>&quot;Astor, Mrs. John Jacob (Madele…</td><td>&quot;female&quot;</td><td>18.0</td><td>1</td><td>0</td><td>&quot;PC 17757&quot;</td><td>227.525</td><td>&quot;C62 C64&quot;</td><td>&quot;C&quot;</td></tr><tr><td>702</td><td>1</td><td>1</td><td>&quot;Silverthorne, Mr. Spencer Vict…</td><td>&quot;male&quot;</td><td>35.0</td><td>0</td><td>0</td><td>&quot;PC 17475&quot;</td><td>26.2875</td><td>&quot;E24&quot;</td><td>&quot;S&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 12)\n",
       "┌─────────────┬──────────┬────────┬──────────────────┬───┬──────────┬─────────┬─────────┬──────────┐\n",
       "│ PassengerId ┆ Survived ┆ Pclass ┆ Name             ┆ … ┆ Ticket   ┆ Fare    ┆ Cabin   ┆ Embarked │\n",
       "│ ---         ┆ ---      ┆ ---    ┆ ---              ┆   ┆ ---      ┆ ---     ┆ ---     ┆ ---      │\n",
       "│ i64         ┆ i64      ┆ i64    ┆ str              ┆   ┆ str      ┆ f64     ┆ str     ┆ str      │\n",
       "╞═════════════╪══════════╪════════╪══════════════════╪═══╪══════════╪═════════╪═════════╪══════════╡\n",
       "│ 701         ┆ 1        ┆ 1      ┆ Astor, Mrs. John ┆ … ┆ PC 17757 ┆ 227.525 ┆ C62 C64 ┆ C        │\n",
       "│             ┆          ┆        ┆ Jacob (Madele…   ┆   ┆          ┆         ┆         ┆          │\n",
       "│ 702         ┆ 1        ┆ 1      ┆ Silverthorne,    ┆ … ┆ PC 17475 ┆ 26.2875 ┆ E24     ┆ S        │\n",
       "│             ┆          ┆        ┆ Mr. Spencer      ┆   ┆          ┆         ┆         ┆          │\n",
       "│             ┆          ┆        ┆ Vict…            ┆   ┆          ┆         ┆         ┆          │\n",
       "└─────────────┴──────────┴────────┴──────────────────┴───┴──────────┴─────────┴─────────┴──────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_csv(\n",
    "    csv_directory / \"*.csv\"\n",
    ").head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85152669",
   "metadata": {},
   "source": [
    "#### What happens when using the wildcard pattern `*`?\n",
    "\n",
    "1. Make a list of the files that match the pattern\n",
    "2. Calls `scan_csv` on each file to make a list of `LazyFrames`\n",
    "3. Does a vertical `concatenation` of the `LazyFrames`\n",
    "4. Calls `collect` to return a `DataFrame`\n",
    "\n",
    "`read_csv` with `*` is an automated version of the lazy mode.\n",
    "\n",
    "### What happens if there is a potential optimization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa30b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>701</td><td>1</td><td>1</td><td>&quot;Astor, Mrs. John Jacob (Madele…</td><td>&quot;female&quot;</td><td>18.0</td><td>1</td><td>0</td><td>&quot;PC 17757&quot;</td><td>227.525</td><td>&quot;C62 C64&quot;</td><td>&quot;C&quot;</td></tr><tr><td>702</td><td>1</td><td>1</td><td>&quot;Silverthorne, Mr. Spencer Vict…</td><td>&quot;male&quot;</td><td>35.0</td><td>0</td><td>0</td><td>&quot;PC 17475&quot;</td><td>26.2875</td><td>&quot;E24&quot;</td><td>&quot;S&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 12)\n",
       "┌─────────────┬──────────┬────────┬──────────────────┬───┬──────────┬─────────┬─────────┬──────────┐\n",
       "│ PassengerId ┆ Survived ┆ Pclass ┆ Name             ┆ … ┆ Ticket   ┆ Fare    ┆ Cabin   ┆ Embarked │\n",
       "│ ---         ┆ ---      ┆ ---    ┆ ---              ┆   ┆ ---      ┆ ---     ┆ ---     ┆ ---      │\n",
       "│ i64         ┆ i64      ┆ i64    ┆ str              ┆   ┆ str      ┆ f64     ┆ str     ┆ str      │\n",
       "╞═════════════╪══════════╪════════╪══════════════════╪═══╪══════════╪═════════╪═════════╪══════════╡\n",
       "│ 701         ┆ 1        ┆ 1      ┆ Astor, Mrs. John ┆ … ┆ PC 17757 ┆ 227.525 ┆ C62 C64 ┆ C        │\n",
       "│             ┆          ┆        ┆ Jacob (Madele…   ┆   ┆          ┆         ┆         ┆          │\n",
       "│ 702         ┆ 1        ┆ 1      ┆ Silverthorne,    ┆ … ┆ PC 17475 ┆ 26.2875 ┆ E24     ┆ S        │\n",
       "│             ┆          ┆        ┆ Mr. Spencer      ┆   ┆          ┆         ┆         ┆          │\n",
       "│             ┆          ┆        ┆ Vict…            ┆   ┆          ┆         ┆         ┆          │\n",
       "└─────────────┴──────────┴────────┴──────────────────┴───┴──────────┴─────────┴─────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_csv(\n",
    "    csv_directory / \"*.csv\"\n",
    ").filter(\n",
    "    pl.col(\"Pclass\") == 1\n",
    ").head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a92314",
   "metadata": {},
   "source": [
    "Actually, Polars reads all csv files `into memory` and concatenated, filter, and return them.\n",
    "\n",
    "### Reading from a list of file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa0484b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>0</td><td>3</td><td>&quot;Braund, Mr. Owen Harris&quot;</td><td>&quot;male&quot;</td><td>22.0</td><td>1</td><td>0</td><td>&quot;A/5 21171&quot;</td><td>7.25</td><td>null</td><td>&quot;S&quot;</td></tr><tr><td>2</td><td>1</td><td>1</td><td>&quot;Cumings, Mrs. John Bradley (Fl…</td><td>&quot;female&quot;</td><td>38.0</td><td>1</td><td>0</td><td>&quot;PC 17599&quot;</td><td>71.2833</td><td>&quot;C85&quot;</td><td>&quot;C&quot;</td></tr><tr><td>3</td><td>1</td><td>3</td><td>&quot;Heikkinen, Miss. Laina&quot;</td><td>&quot;female&quot;</td><td>26.0</td><td>0</td><td>0</td><td>&quot;STON/O2. 3101282&quot;</td><td>7.925</td><td>null</td><td>&quot;S&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 12)\n",
       "┌─────────────┬──────────┬────────┬───────────────────┬───┬───────────┬─────────┬───────┬──────────┐\n",
       "│ PassengerId ┆ Survived ┆ Pclass ┆ Name              ┆ … ┆ Ticket    ┆ Fare    ┆ Cabin ┆ Embarked │\n",
       "│ ---         ┆ ---      ┆ ---    ┆ ---               ┆   ┆ ---       ┆ ---     ┆ ---   ┆ ---      │\n",
       "│ i64         ┆ i64      ┆ i64    ┆ str               ┆   ┆ str       ┆ f64     ┆ str   ┆ str      │\n",
       "╞═════════════╪══════════╪════════╪═══════════════════╪═══╪═══════════╪═════════╪═══════╪══════════╡\n",
       "│ 1           ┆ 0        ┆ 3      ┆ Braund, Mr. Owen  ┆ … ┆ A/5 21171 ┆ 7.25    ┆ null  ┆ S        │\n",
       "│             ┆          ┆        ┆ Harris            ┆   ┆           ┆         ┆       ┆          │\n",
       "│ 2           ┆ 1        ┆ 1      ┆ Cumings, Mrs.     ┆ … ┆ PC 17599  ┆ 71.2833 ┆ C85   ┆ C        │\n",
       "│             ┆          ┆        ┆ John Bradley (Fl… ┆   ┆           ┆         ┆       ┆          │\n",
       "│ 3           ┆ 1        ┆ 3      ┆ Heikkinen, Miss.  ┆ … ┆ STON/O2.  ┆ 7.925   ┆ null  ┆ S        │\n",
       "│             ┆          ┆        ┆ Laina             ┆   ┆ 3101282   ┆         ┆       ┆          │\n",
       "└─────────────┴──────────┴────────┴───────────────────┴───┴───────────┴─────────┴───────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_list = [csv_directory / \"train.csv\",csv_directory / \"test.csv\"]\n",
    "\n",
    "pl.concat(\n",
    "    [pl.read_csv(csv_path) for csv_path in file_path_list]\n",
    ").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c3b36",
   "metadata": {},
   "source": [
    "## Scanning CSVs in lazy mode\n",
    "\n",
    "### Scanning multiple files with a wildcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143ae7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csv SCAN [data/csv/multiple_csv/test.csv, data/csv/multiple_csv/train.csv]\n",
      "PROJECT */12 COLUMNS\n",
      "SELECTION: [(col(\"Age\")) > (50.0)]\n",
      "ESTIMATED ROWS: 891\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pl.scan_csv(\n",
    "        csv_directory / \"*.csv\"\n",
    "    ).filter(\n",
    "        pl.col(\"Age\") > 50\n",
    "    ).explain()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (64, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>715</td><td>0</td><td>2</td><td>&quot;Greenberg, Mr. Samuel&quot;</td><td>&quot;male&quot;</td><td>52.0</td><td>0</td><td>0</td><td>&quot;250647&quot;</td><td>13.0</td><td>null</td><td>&quot;S&quot;</td></tr><tr><td>746</td><td>0</td><td>1</td><td>&quot;Crosby, Capt. Edward Gifford&quot;</td><td>&quot;male&quot;</td><td>70.0</td><td>1</td><td>1</td><td>&quot;WE/P 5735&quot;</td><td>71.0</td><td>&quot;B22&quot;</td><td>&quot;S&quot;</td></tr><tr><td>766</td><td>1</td><td>1</td><td>&quot;Hogeboom, Mrs. John C (Anna An…</td><td>&quot;female&quot;</td><td>51.0</td><td>1</td><td>0</td><td>&quot;13502&quot;</td><td>77.9583</td><td>&quot;D11&quot;</td><td>&quot;S&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>685</td><td>0</td><td>2</td><td>&quot;Brown, Mr. Thomas William Solo…</td><td>&quot;male&quot;</td><td>60.0</td><td>1</td><td>1</td><td>&quot;29750&quot;</td><td>39.0</td><td>null</td><td>&quot;S&quot;</td></tr><tr><td>695</td><td>0</td><td>1</td><td>&quot;Weir, Col. John&quot;</td><td>&quot;male&quot;</td><td>60.0</td><td>0</td><td>0</td><td>&quot;113800&quot;</td><td>26.55</td><td>null</td><td>&quot;S&quot;</td></tr><tr><td>696</td><td>0</td><td>2</td><td>&quot;Chapman, Mr. Charles Henry&quot;</td><td>&quot;male&quot;</td><td>52.0</td><td>0</td><td>0</td><td>&quot;248731&quot;</td><td>13.5</td><td>null</td><td>&quot;S&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (64, 12)\n",
       "┌─────────────┬──────────┬────────┬───────────────────┬───┬───────────┬─────────┬───────┬──────────┐\n",
       "│ PassengerId ┆ Survived ┆ Pclass ┆ Name              ┆ … ┆ Ticket    ┆ Fare    ┆ Cabin ┆ Embarked │\n",
       "│ ---         ┆ ---      ┆ ---    ┆ ---               ┆   ┆ ---       ┆ ---     ┆ ---   ┆ ---      │\n",
       "│ i64         ┆ i64      ┆ i64    ┆ str               ┆   ┆ str       ┆ f64     ┆ str   ┆ str      │\n",
       "╞═════════════╪══════════╪════════╪═══════════════════╪═══╪═══════════╪═════════╪═══════╪══════════╡\n",
       "│ 715         ┆ 0        ┆ 2      ┆ Greenberg, Mr.    ┆ … ┆ 250647    ┆ 13.0    ┆ null  ┆ S        │\n",
       "│             ┆          ┆        ┆ Samuel            ┆   ┆           ┆         ┆       ┆          │\n",
       "│ 746         ┆ 0        ┆ 1      ┆ Crosby, Capt.     ┆ … ┆ WE/P 5735 ┆ 71.0    ┆ B22   ┆ S        │\n",
       "│             ┆          ┆        ┆ Edward Gifford    ┆   ┆           ┆         ┆       ┆          │\n",
       "│ 766         ┆ 1        ┆ 1      ┆ Hogeboom, Mrs.    ┆ … ┆ 13502     ┆ 77.9583 ┆ D11   ┆ S        │\n",
       "│             ┆          ┆        ┆ John C (Anna An…  ┆   ┆           ┆         ┆       ┆          │\n",
       "│ …           ┆ …        ┆ …      ┆ …                 ┆ … ┆ …         ┆ …       ┆ …     ┆ …        │\n",
       "│ 685         ┆ 0        ┆ 2      ┆ Brown, Mr. Thomas ┆ … ┆ 29750     ┆ 39.0    ┆ null  ┆ S        │\n",
       "│             ┆          ┆        ┆ William Solo…     ┆   ┆           ┆         ┆       ┆          │\n",
       "│ 695         ┆ 0        ┆ 1      ┆ Weir, Col. John   ┆ … ┆ 113800    ┆ 26.55   ┆ null  ┆ S        │\n",
       "│ 696         ┆ 0        ┆ 2      ┆ Chapman, Mr.      ┆ … ┆ 248731    ┆ 13.5    ┆ null  ┆ S        │\n",
       "│             ┆          ┆        ┆ Charles Henry     ┆   ┆           ┆         ┆       ┆          │\n",
       "└─────────────┴──────────┴────────┴───────────────────┴───┴───────────┴─────────┴───────┴──────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.scan_csv(\n",
    "        csv_directory / \"*.csv\"\n",
    "    ).filter(\n",
    "        pl.col(\"Age\") > 50\n",
    "    ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198a025",
   "metadata": {},
   "source": [
    "## Handling variations in column names\n",
    "\n",
    "We can't concatenate CSVs that have different column names with `pl.scan_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c6906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pl.DataFrame({\"int_column\": [0, 1, 2]})\n",
    "\n",
    "df2 = pl.DataFrame({\"Int_Column\": [3, 4]})\n",
    "\n",
    "mismatched_column_names_path = Path('data/csv/mismatched_column_names/')\n",
    "\n",
    "if not mismatched_column_names_path.exists():\n",
    "    mismatched_column_names_path.mkdir()\n",
    "\n",
    "df1.write_csv(mismatched_column_names_path / \"df1.csv\")\n",
    "df2.write_csv(mismatched_column_names_path / \"df2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4520527",
   "metadata": {},
   "source": [
    "If we try to call `pl.scan_csv` with a `*` we get an `Exception`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c798e059",
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "schema names differ: got int_column, expected Int_Column\n\nThis error occurred with the following context stack:\n\t[1] 'csv scan'\n\t[2] 'sink'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mComputeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscan_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmismatched_column_names_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdf*.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\polars-learning-qrMaRlBI-py3.13\\Lib\\site-packages\\polars\\_utils\\deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\polars-learning-qrMaRlBI-py3.13\\Lib\\site-packages\\polars\\lazyframe\\opt_flags.py:324\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    323\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dinni\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\polars-learning-qrMaRlBI-py3.13\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2429\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2427\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2428\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mComputeError\u001b[39m: schema names differ: got int_column, expected Int_Column\n\nThis error occurred with the following context stack:\n\t[1] 'csv scan'\n\t[2] 'sink'\n"
     ]
    }
   ],
   "source": [
    "pl.scan_csv(mismatched_column_names_path / 'df*.csv').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689d4785",
   "metadata": {},
   "source": [
    "We can use `with_column_names` parameter to solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e14d1225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>int_column</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌────────────┐\n",
       "│ int_column │\n",
       "│ ---        │\n",
       "│ i64        │\n",
       "╞════════════╡\n",
       "│ 0          │\n",
       "│ 1          │\n",
       "│ 2          │\n",
       "│ 3          │\n",
       "│ 4          │\n",
       "└────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.scan_csv(\n",
    "    mismatched_column_names_path / 'df*.csv',\n",
    "    with_column_names=lambda cols: [col.lower() for col in cols]\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242bf40",
   "metadata": {},
   "source": [
    "### Scanning from a list of file paths in lazy mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef9c5538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LazyFrame at 0x20C30D1B6A0>, <LazyFrame at 0x20C30E28B90>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_list = [\n",
    "    'data/csv/multiple_csv/train.csv',\n",
    "    'data/csv/multiple_csv/test.csv'\n",
    "]\n",
    "\n",
    "queries_list = [\n",
    "    pl.scan_csv(csv_path) for csv_path in files_list\n",
    "]\n",
    "\n",
    "queries_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb884587",
   "metadata": {},
   "source": [
    "The `queries_list` is a `list` of `LazyFrames`\n",
    "\n",
    "Polars can evaluate a `list` of `LazyFrames` with `pl.collect_all` and the output is a `list` of `DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f115a1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>0</td><td>3</td><td>&quot;Braund, Mr. Owen Harris&quot;</td><td>&quot;male&quot;</td><td>22.0</td><td>1</td><td>0</td><td>&quot;A/5 21171&quot;</td><td>7.25</td><td>null</td><td>&quot;S&quot;</td></tr><tr><td>2</td><td>1</td><td>1</td><td>&quot;Cumings, Mrs. John Bradley (Fl…</td><td>&quot;female&quot;</td><td>38.0</td><td>1</td><td>0</td><td>&quot;PC 17599&quot;</td><td>71.2833</td><td>&quot;C85&quot;</td><td>&quot;C&quot;</td></tr><tr><td>3</td><td>1</td><td>3</td><td>&quot;Heikkinen, Miss. Laina&quot;</td><td>&quot;female&quot;</td><td>26.0</td><td>0</td><td>0</td><td>&quot;STON/O2. 3101282&quot;</td><td>7.925</td><td>null</td><td>&quot;S&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 12)\n",
       "┌─────────────┬──────────┬────────┬───────────────────┬───┬───────────┬─────────┬───────┬──────────┐\n",
       "│ PassengerId ┆ Survived ┆ Pclass ┆ Name              ┆ … ┆ Ticket    ┆ Fare    ┆ Cabin ┆ Embarked │\n",
       "│ ---         ┆ ---      ┆ ---    ┆ ---               ┆   ┆ ---       ┆ ---     ┆ ---   ┆ ---      │\n",
       "│ i64         ┆ i64      ┆ i64    ┆ str               ┆   ┆ str       ┆ f64     ┆ str   ┆ str      │\n",
       "╞═════════════╪══════════╪════════╪═══════════════════╪═══╪═══════════╪═════════╪═══════╪══════════╡\n",
       "│ 1           ┆ 0        ┆ 3      ┆ Braund, Mr. Owen  ┆ … ┆ A/5 21171 ┆ 7.25    ┆ null  ┆ S        │\n",
       "│             ┆          ┆        ┆ Harris            ┆   ┆           ┆         ┆       ┆          │\n",
       "│ 2           ┆ 1        ┆ 1      ┆ Cumings, Mrs.     ┆ … ┆ PC 17599  ┆ 71.2833 ┆ C85   ┆ C        │\n",
       "│             ┆          ┆        ┆ John Bradley (Fl… ┆   ┆           ┆         ┆       ┆          │\n",
       "│ 3           ┆ 1        ┆ 3      ┆ Heikkinen, Miss.  ┆ … ┆ STON/O2.  ┆ 7.925   ┆ null  ┆ S        │\n",
       "│             ┆          ┆        ┆ Laina             ┆   ┆ 3101282   ┆         ┆       ┆          │\n",
       "└─────────────┴──────────┴────────┴───────────────────┴───┴───────────┴─────────┴───────┴──────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.concat(\n",
    "    queries_list\n",
    ").collect().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382efe16",
   "metadata": {},
   "source": [
    "## Discovering file paths\n",
    "\n",
    "In some cases we want an easy way to find all the CSVs in sub-directories.\n",
    "\n",
    "We can use `PyArrow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72a918f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "\n",
    "dataset = ds.dataset(\n",
    "    csv_directory,\n",
    "    format=\"csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "858394ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/csv/multiple_csv/test.csv', 'data/csv/multiple_csv/train.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0860cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>701</td><td>1</td><td>1</td><td>&quot;Astor, Mrs. John Jacob (Madele…</td><td>&quot;female&quot;</td><td>18.0</td><td>1</td><td>0</td><td>&quot;PC 17757&quot;</td><td>227.525</td><td>&quot;C62 C64&quot;</td><td>&quot;C&quot;</td></tr><tr><td>702</td><td>1</td><td>1</td><td>&quot;Silverthorne, Mr. Spencer Vict…</td><td>&quot;male&quot;</td><td>35.0</td><td>0</td><td>0</td><td>&quot;PC 17475&quot;</td><td>26.2875</td><td>&quot;E24&quot;</td><td>&quot;S&quot;</td></tr><tr><td>703</td><td>0</td><td>3</td><td>&quot;Barbara, Miss. Saiide&quot;</td><td>&quot;female&quot;</td><td>18.0</td><td>0</td><td>1</td><td>&quot;2691&quot;</td><td>14.4542</td><td>&quot;&quot;</td><td>&quot;C&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 12)\n",
       "┌─────────────┬──────────┬────────┬──────────────────┬───┬──────────┬─────────┬─────────┬──────────┐\n",
       "│ PassengerId ┆ Survived ┆ Pclass ┆ Name             ┆ … ┆ Ticket   ┆ Fare    ┆ Cabin   ┆ Embarked │\n",
       "│ ---         ┆ ---      ┆ ---    ┆ ---              ┆   ┆ ---      ┆ ---     ┆ ---     ┆ ---      │\n",
       "│ i64         ┆ i64      ┆ i64    ┆ str              ┆   ┆ str      ┆ f64     ┆ str     ┆ str      │\n",
       "╞═════════════╪══════════╪════════╪══════════════════╪═══╪══════════╪═════════╪═════════╪══════════╡\n",
       "│ 701         ┆ 1        ┆ 1      ┆ Astor, Mrs. John ┆ … ┆ PC 17757 ┆ 227.525 ┆ C62 C64 ┆ C        │\n",
       "│             ┆          ┆        ┆ Jacob (Madele…   ┆   ┆          ┆         ┆         ┆          │\n",
       "│ 702         ┆ 1        ┆ 1      ┆ Silverthorne,    ┆ … ┆ PC 17475 ┆ 26.2875 ┆ E24     ┆ S        │\n",
       "│             ┆          ┆        ┆ Mr. Spencer      ┆   ┆          ┆         ┆         ┆          │\n",
       "│             ┆          ┆        ┆ Vict…            ┆   ┆          ┆         ┆         ┆          │\n",
       "│ 703         ┆ 0        ┆ 3      ┆ Barbara, Miss.   ┆ … ┆ 2691     ┆ 14.4542 ┆         ┆ C        │\n",
       "│             ┆          ┆        ┆ Saiide           ┆   ┆          ┆         ┆         ┆          │\n",
       "└─────────────┴──────────┴────────┴──────────────────┴───┴──────────┴─────────┴─────────┴──────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.from_arrow(\n",
    "    dataset.to_table()\n",
    ").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6ed7639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Pclass</th><th>Age</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>3</td><td>74.0</td></tr><tr><td>1</td><td>71.0</td></tr><tr><td>3</td><td>70.5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬──────┐\n",
       "│ Pclass ┆ Age  │\n",
       "│ ---    ┆ ---  │\n",
       "│ i64    ┆ f64  │\n",
       "╞════════╪══════╡\n",
       "│ 3      ┆ 74.0 │\n",
       "│ 1      ┆ 71.0 │\n",
       "│ 3      ┆ 70.5 │\n",
       "└────────┴──────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.from_arrow(\n",
    "    dataset.to_table(\n",
    "        columns=[\"Pclass\", \"Age\"],\n",
    "        filter=ds.field(\"Age\") > 70\n",
    "    )\n",
    ").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd5996",
   "metadata": {},
   "source": [
    "Use `PyArrow` when there is a more complicated directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72470951",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "The NYC taxi dataset CSV has 1000 rows containing records from different days.\n",
    "\n",
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ea1f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyccsv_file = \"data/nyc_trip_data_1k.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166364e",
   "metadata": {},
   "source": [
    "- read the CSV\n",
    "- add a column that records the date from the `pickup` datetime\n",
    "- partition the `DataFrame` into a dictionary that maps dates to the `DataFrame` for that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebe5e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyDfDict = (\n",
    "    pl.read_csv(nyccsv_file,try_parse_dates=True)\n",
    "    .with_columns(\n",
    "    pl.col(\"pickup\").dt.truncate(\"1d\").dt.strftime(\"%Y-%m-%d\").alias(\"pickup_day\")\n",
    "    )\n",
    "    .partition_by(by=[\"pickup_day\"],as_dict=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e1b1e",
   "metadata": {},
   "source": [
    "The keys of the `dailyDfDict` are the string dates for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb4648c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('2022-01-01',), ('2022-01-02',), ('2022-01-03',), ('2022-01-04',), ('2022-01-05',), ('2022-01-06',), ('2022-01-07',), ('2022-01-08',), ('2022-01-09',), ('2022-01-10',), ('2022-01-11',), ('2022-01-12',), ('2022-01-13',), ('2022-01-14',), ('2022-02-01',)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyDfDict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa718a",
   "metadata": {},
   "source": [
    "The values for each key is a `DataFrame` for that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c43b9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>pickup</th><th>dropoff</th><th>passenger_count</th><th>trip_distance</th><th>fare_amount</th><th>tip_amount</th><th>pickup_day</th></tr><tr><td>str</td><td>datetime[μs]</td><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;id1&quot;</td><td>2022-01-01 00:04:14</td><td>2022-01-01 00:26:12</td><td>1.0</td><td>10.83</td><td>31.0</td><td>0.0</td><td>&quot;2022-01-01&quot;</td></tr><tr><td>&quot;id2&quot;</td><td>2022-01-01 00:32:17</td><td>2022-01-01 00:49:23</td><td>1.0</td><td>3.97</td><td>14.5</td><td>3.66</td><td>&quot;2022-01-01&quot;</td></tr><tr><td>&quot;id8&quot;</td><td>2022-01-01 00:40:58</td><td>2022-01-01 01:00:59</td><td>4.0</td><td>8.44</td><td>25.5</td><td>0.0</td><td>&quot;2022-01-01&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 8)\n",
       "┌──────────┬────────────┬────────────┬────────────┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ VendorID ┆ pickup     ┆ dropoff    ┆ passenger_ ┆ trip_dista ┆ fare_amou ┆ tip_amoun ┆ pickup_da │\n",
       "│ ---      ┆ ---        ┆ ---        ┆ count      ┆ nce        ┆ nt        ┆ t         ┆ y         │\n",
       "│ str      ┆ datetime[μ ┆ datetime[μ ┆ ---        ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│          ┆ s]         ┆ s]         ┆ f64        ┆ f64        ┆ f64       ┆ f64       ┆ str       │\n",
       "╞══════════╪════════════╪════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ id1      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 1.0        ┆ 10.83      ┆ 31.0      ┆ 0.0       ┆ 2022-01-0 │\n",
       "│          ┆ 00:04:14   ┆ 00:26:12   ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│ id2      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 1.0        ┆ 3.97       ┆ 14.5      ┆ 3.66      ┆ 2022-01-0 │\n",
       "│          ┆ 00:32:17   ┆ 00:49:23   ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│ id8      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 4.0        ┆ 8.44       ┆ 25.5      ┆ 0.0       ┆ 2022-01-0 │\n",
       "│          ┆ 00:40:58   ┆ 01:00:59   ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "└──────────┴────────────┴────────────┴────────────┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyDfDict['2022-01-01',].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df83b9c",
   "metadata": {},
   "source": [
    "We now create a partitioned directory called `daily_nyc` for the data.\n",
    "\n",
    "The name of each sub-directory is a date.\n",
    "\n",
    "The content of each sub-directory is the CSV for that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e322246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the new directory\n",
    "nyccsv_directory = Path(\"data/csv/daily_nyc\")\n",
    "\n",
    "# Create the new directory if it doesn't already exist\n",
    "nyccsv_directory.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "# Loop through each date\n",
    "for (day,), df in dailyDfDict.items():\n",
    "    # Create a Path object for that date\n",
    "    dailyDirectory = (nyccsv_directory / day)\n",
    "    # Create the sub-directory for that date\n",
    "    dailyDirectory.mkdir(parents=True,exist_ok=True)\n",
    "    # Write a CSV called daily.csv\n",
    "    df.write_csv(dailyDirectory / \"daily.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de4f34",
   "metadata": {},
   "source": [
    "### Now on to the exercise!\n",
    "\n",
    "Read all the CSV files in eager mode using a path with wildcards for the final directory name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd7e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>pickup</th><th>dropoff</th><th>passenger_count</th><th>trip_distance</th><th>fare_amount</th><th>tip_amount</th><th>pickup_day</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;id1&quot;</td><td>&quot;2022-01-01T00:04:14.000000&quot;</td><td>&quot;2022-01-01T00:26:12.000000&quot;</td><td>1.0</td><td>10.83</td><td>31.0</td><td>0.0</td><td>&quot;2022-01-01&quot;</td></tr><tr><td>&quot;id2&quot;</td><td>&quot;2022-01-01T00:32:17.000000&quot;</td><td>&quot;2022-01-01T00:49:23.000000&quot;</td><td>1.0</td><td>3.97</td><td>14.5</td><td>3.66</td><td>&quot;2022-01-01&quot;</td></tr><tr><td>&quot;id8&quot;</td><td>&quot;2022-01-01T00:40:58.000000&quot;</td><td>&quot;2022-01-01T01:00:59.000000&quot;</td><td>4.0</td><td>8.44</td><td>25.5</td><td>0.0</td><td>&quot;2022-01-01&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;id2&quot;</td><td>&quot;2022-01-14T18:34:11.000000&quot;</td><td>&quot;2022-01-14T18:39:18.000000&quot;</td><td>3.0</td><td>0.92</td><td>5.5</td><td>2.45</td><td>&quot;2022-01-14&quot;</td></tr><tr><td>&quot;id0&quot;</td><td>&quot;2022-01-14T18:49:08.000000&quot;</td><td>&quot;2022-01-14T18:54:08.000000&quot;</td><td>0.0</td><td>0.8</td><td>5.0</td><td>2.3</td><td>&quot;2022-01-14&quot;</td></tr><tr><td>&quot;id5&quot;</td><td>&quot;2022-02-01T03:00:05.000000&quot;</td><td>&quot;2022-02-01T03:15:08.000000&quot;</td><td>3.0</td><td>2.62</td><td>12.0</td><td>0.0</td><td>&quot;2022-02-01&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000, 8)\n",
       "┌──────────┬────────────┬────────────┬────────────┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ VendorID ┆ pickup     ┆ dropoff    ┆ passenger_ ┆ trip_dista ┆ fare_amou ┆ tip_amoun ┆ pickup_da │\n",
       "│ ---      ┆ ---        ┆ ---        ┆ count      ┆ nce        ┆ nt        ┆ t         ┆ y         │\n",
       "│ str      ┆ str        ┆ str        ┆ ---        ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│          ┆            ┆            ┆ f64        ┆ f64        ┆ f64       ┆ f64       ┆ str       │\n",
       "╞══════════╪════════════╪════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ id1      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 1.0        ┆ 10.83      ┆ 31.0      ┆ 0.0       ┆ 2022-01-0 │\n",
       "│          ┆ T00:04:14. ┆ T00:26:12. ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ id2      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 1.0        ┆ 3.97       ┆ 14.5      ┆ 3.66      ┆ 2022-01-0 │\n",
       "│          ┆ T00:32:17. ┆ T00:49:23. ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ id8      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 4.0        ┆ 8.44       ┆ 25.5      ┆ 0.0       ┆ 2022-01-0 │\n",
       "│          ┆ T00:40:58. ┆ T01:00:59. ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ …        ┆ …          ┆ …          ┆ …          ┆ …          ┆ …         ┆ …         ┆ …         │\n",
       "│ id2      ┆ 2022-01-14 ┆ 2022-01-14 ┆ 3.0        ┆ 0.92       ┆ 5.5       ┆ 2.45      ┆ 2022-01-1 │\n",
       "│          ┆ T18:34:11. ┆ T18:39:18. ┆            ┆            ┆           ┆           ┆ 4         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ id0      ┆ 2022-01-14 ┆ 2022-01-14 ┆ 0.0        ┆ 0.8        ┆ 5.0       ┆ 2.3       ┆ 2022-01-1 │\n",
       "│          ┆ T18:49:08. ┆ T18:54:08. ┆            ┆            ┆           ┆           ┆ 4         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ id5      ┆ 2022-02-01 ┆ 2022-02-01 ┆ 3.0        ┆ 2.62       ┆ 12.0      ┆ 0.0       ┆ 2022-02-0 │\n",
       "│          ┆ T03:00:05. ┆ T03:15:08. ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "└──────────┴────────────┴────────────┴────────────┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_csv(\"data/csv/daily_nyc/*/daily.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b443e",
   "metadata": {},
   "source": [
    "Read the CSV files in eager mode using:\n",
    "- a `glob` and a `generator`\n",
    "- a concatenation of the list of `DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b5a02b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths_generator = nyccsv_directory.glob(\"*/*.csv\")\n",
    "\n",
    "pl.concat(\n",
    "    [pl.read_csv(csv_path) for csv_path in file_path_list]\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4674e8",
   "metadata": {},
   "source": [
    "Read all the CSV files in lazy mode using a path with wildcards for the final directory name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93ba005e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>pickup</th><th>dropoff</th><th>passenger_count</th><th>trip_distance</th><th>fare_amount</th><th>tip_amount</th><th>pickup_day</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;id1&quot;</td><td>&quot;2022-01-01T00:04:14.000000&quot;</td><td>&quot;2022-01-01T00:26:12.000000&quot;</td><td>1.0</td><td>10.83</td><td>31.0</td><td>0.0</td><td>&quot;2022-01-01&quot;</td></tr><tr><td>&quot;id2&quot;</td><td>&quot;2022-01-01T00:32:17.000000&quot;</td><td>&quot;2022-01-01T00:49:23.000000&quot;</td><td>1.0</td><td>3.97</td><td>14.5</td><td>3.66</td><td>&quot;2022-01-01&quot;</td></tr><tr><td>&quot;id8&quot;</td><td>&quot;2022-01-01T00:40:58.000000&quot;</td><td>&quot;2022-01-01T01:00:59.000000&quot;</td><td>4.0</td><td>8.44</td><td>25.5</td><td>0.0</td><td>&quot;2022-01-01&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;id2&quot;</td><td>&quot;2022-01-14T18:34:11.000000&quot;</td><td>&quot;2022-01-14T18:39:18.000000&quot;</td><td>3.0</td><td>0.92</td><td>5.5</td><td>2.45</td><td>&quot;2022-01-14&quot;</td></tr><tr><td>&quot;id0&quot;</td><td>&quot;2022-01-14T18:49:08.000000&quot;</td><td>&quot;2022-01-14T18:54:08.000000&quot;</td><td>0.0</td><td>0.8</td><td>5.0</td><td>2.3</td><td>&quot;2022-01-14&quot;</td></tr><tr><td>&quot;id5&quot;</td><td>&quot;2022-02-01T03:00:05.000000&quot;</td><td>&quot;2022-02-01T03:15:08.000000&quot;</td><td>3.0</td><td>2.62</td><td>12.0</td><td>0.0</td><td>&quot;2022-02-01&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000, 8)\n",
       "┌──────────┬────────────┬────────────┬────────────┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ VendorID ┆ pickup     ┆ dropoff    ┆ passenger_ ┆ trip_dista ┆ fare_amou ┆ tip_amoun ┆ pickup_da │\n",
       "│ ---      ┆ ---        ┆ ---        ┆ count      ┆ nce        ┆ nt        ┆ t         ┆ y         │\n",
       "│ str      ┆ str        ┆ str        ┆ ---        ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│          ┆            ┆            ┆ f64        ┆ f64        ┆ f64       ┆ f64       ┆ str       │\n",
       "╞══════════╪════════════╪════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ id1      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 1.0        ┆ 10.83      ┆ 31.0      ┆ 0.0       ┆ 2022-01-0 │\n",
       "│          ┆ T00:04:14. ┆ T00:26:12. ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ id2      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 1.0        ┆ 3.97       ┆ 14.5      ┆ 3.66      ┆ 2022-01-0 │\n",
       "│          ┆ T00:32:17. ┆ T00:49:23. ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ id8      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 4.0        ┆ 8.44       ┆ 25.5      ┆ 0.0       ┆ 2022-01-0 │\n",
       "│          ┆ T00:40:58. ┆ T01:00:59. ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ …        ┆ …          ┆ …          ┆ …          ┆ …          ┆ …         ┆ …         ┆ …         │\n",
       "│ id2      ┆ 2022-01-14 ┆ 2022-01-14 ┆ 3.0        ┆ 0.92       ┆ 5.5       ┆ 2.45      ┆ 2022-01-1 │\n",
       "│          ┆ T18:34:11. ┆ T18:39:18. ┆            ┆            ┆           ┆           ┆ 4         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ id0      ┆ 2022-01-14 ┆ 2022-01-14 ┆ 0.0        ┆ 0.8        ┆ 5.0       ┆ 2.3       ┆ 2022-01-1 │\n",
       "│          ┆ T18:49:08. ┆ T18:54:08. ┆            ┆            ┆           ┆           ┆ 4         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "│ id5      ┆ 2022-02-01 ┆ 2022-02-01 ┆ 3.0        ┆ 2.62       ┆ 12.0      ┆ 0.0       ┆ 2022-02-0 │\n",
       "│          ┆ T03:00:05. ┆ T03:15:08. ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│          ┆ 000000     ┆ 000000     ┆            ┆            ┆           ┆           ┆           │\n",
       "└──────────┴────────────┴────────────┴────────────┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.scan_csv(\"data/csv/daily_nyc/*/daily.csv\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d88a9",
   "metadata": {},
   "source": [
    "Read all the CSVs in lazy mode **between 2022-01-01 and 2022-01-09** inclusive\n",
    "\n",
    "- Scan the required `DataFrames` by iterating through the generator\n",
    "- Call `collect_all` to evaluate all the `LazyFrames`\n",
    "- `concat` all the `DataFrames`\n",
    "\n",
    "If you want a hint about filtering the dates expand the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "970b6788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(652, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nycfile_paths_generator = nyccsv_directory.glob(\"*/daily.csv\")\n",
    "\n",
    "pl.concat(\n",
    "    pl.collect_all(\n",
    "        [pl.scan_csv(csv_path) for csv_path in nycfile_paths_generator if \"2022-01-0\" in csv_path.as_posix()]\n",
    "    )\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bfea57",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Create a PyArrow `dataset` object with all the CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a432ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.dataset(nyccsv_directory, format=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758e212",
   "metadata": {},
   "source": [
    "List all the CSV files in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83aee4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/csv/daily_nyc/2022-01-01/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-02/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-03/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-04/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-05/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-06/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-07/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-08/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-09/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-10/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-11/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-12/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-13/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-01-14/daily.csv',\n",
       " 'data/csv/daily_nyc/2022-02-01/daily.csv']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407733f",
   "metadata": {},
   "source": [
    "Read all the files into a Polars `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00cc07d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>pickup</th><th>dropoff</th><th>passenger_count</th><th>trip_distance</th><th>fare_amount</th><th>tip_amount</th><th>pickup_day</th></tr><tr><td>str</td><td>datetime[ns]</td><td>datetime[ns]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>date</td></tr></thead><tbody><tr><td>&quot;id1&quot;</td><td>2022-01-01 00:04:14</td><td>2022-01-01 00:26:12</td><td>1.0</td><td>10.83</td><td>31.0</td><td>0.0</td><td>2022-01-01</td></tr><tr><td>&quot;id2&quot;</td><td>2022-01-01 00:32:17</td><td>2022-01-01 00:49:23</td><td>1.0</td><td>3.97</td><td>14.5</td><td>3.66</td><td>2022-01-01</td></tr><tr><td>&quot;id8&quot;</td><td>2022-01-01 00:40:58</td><td>2022-01-01 01:00:59</td><td>4.0</td><td>8.44</td><td>25.5</td><td>0.0</td><td>2022-01-01</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 8)\n",
       "┌──────────┬────────────┬────────────┬────────────┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ VendorID ┆ pickup     ┆ dropoff    ┆ passenger_ ┆ trip_dista ┆ fare_amou ┆ tip_amoun ┆ pickup_da │\n",
       "│ ---      ┆ ---        ┆ ---        ┆ count      ┆ nce        ┆ nt        ┆ t         ┆ y         │\n",
       "│ str      ┆ datetime[n ┆ datetime[n ┆ ---        ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│          ┆ s]         ┆ s]         ┆ f64        ┆ f64        ┆ f64       ┆ f64       ┆ date      │\n",
       "╞══════════╪════════════╪════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ id1      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 1.0        ┆ 10.83      ┆ 31.0      ┆ 0.0       ┆ 2022-01-0 │\n",
       "│          ┆ 00:04:14   ┆ 00:26:12   ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│ id2      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 1.0        ┆ 3.97       ┆ 14.5      ┆ 3.66      ┆ 2022-01-0 │\n",
       "│          ┆ 00:32:17   ┆ 00:49:23   ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "│ id8      ┆ 2022-01-01 ┆ 2022-01-01 ┆ 4.0        ┆ 8.44       ┆ 25.5      ┆ 0.0       ┆ 2022-01-0 │\n",
       "│          ┆ 00:40:58   ┆ 01:00:59   ┆            ┆            ┆           ┆           ┆ 1         │\n",
       "└──────────┴────────────┴────────────┴────────────┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.from_arrow(\n",
    "    dataset.to_table()\n",
    ").head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polars-learning-qrMaRlBI-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
